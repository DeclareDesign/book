# Ethics {.unnumbered}



```{r}
#| echo: false
#| include: false
#| purl:  false
source("scripts/before_chapter_script.R")
```

As research designers, we have ethical obligations beyond the requirements of national laws and the regulations of institutional review boards. 

For a long time thinking about research ethics have been guided by the ideas in the [Belmont report](https://www.hhs.gov/ohrp/regulations-and-policy/belmont-report/index.html), that emphasize beneficence, respect for persons, and autonomy. Recently, more attention has been given to principles that extend beyond care for human subjects to include considerations for the well-being of collaborators and partners and the broader social impact of research. Social scientific professional associations have developed principles and guidelines to help think through these issues. Key references include:

- [American Political Science Association ethics guidelines](https://www.apsanet.org/Portals/54/diversity%20and%20inclusion%20prgms/Ethics/Final_Principles%20with%20Guidance%20with%20intro.pdf?ver=2020-04-20-211740-153)
- [American Sociological Association Code of Ethics](https://www.asanet.org/sites/default/files/asa_code_of_ethics-june2018.pdf)
- [American Psychological Association Ethical Principles of Psychologists and Code of Conduct](https://www.apa.org/ethics/code)

The considerations at play vary across context and methods. For example, @teele2020 describes ethical considerations in field experimentation, @humphreys2015reflections focuses on development settings, @slough2020ethics considers the ethics of field experimentation in the context of elections, and @wood2006ethical and @young2020 consider ethical challenges specific to field research in conflict settings. 

However a common meta-principle underlying many of these contributions is the injunction to consider the ethical dimensions of your work ex ante and to report on ethical implications ex post. @lyall2020 specifically connects ethical reflection to ex ante design considerations.

We encourage you to engage with ethical considerations in this way, early in the research design lifecycle. Some design declarations and diagnoses elide ethical considerations. For instance, a declaration that is diagnosand-complete for statistical power may tell you little about the level of care and respect accorded to subjects. Many declarations are diagnosand-complete for bias, but obtaining an unbiased treatment effect estimate is not always the highest goal. 

Ethical diagnosands can be directly incorporated into the declare-diagnose-redesign framework. Diagnosands could include the total cost to participants, how many participants were harmed, the average level of informed consent measured by a survey about comprehension of study goals, or the risks of adverse events. More complex ethical diagnosands may be possible as well: @slough2020ethics provides a formal analysis of the "aggregate electoral impact" diagnosand for experiments that take place in the context of elections. We consider two specific ethical diagnosands here, costs and potential harms, though many others may apply in particular research scenarios.

**Costs.** A common concern is that measurement imposes a cost on subjects, if only by wasting their time. Subjects' time is a valuable resource they often donate willingly to the scientific enterprise by participating in a survey or other measurement. Although subjects' generosity is sometimes repaid with financial compensation, in many scenarios direct payments are not feasible. Regardless of whether subjects are paid, the costs to subjects should be top of mind when designing the study.

**Potential harms.** Different realizations of the data from the same data strategy may differ in their ethical status. Ex-post, a study may not have ended up harming subjects, but ex-ante, there may have been a risk of harm [@young2020]. The project's ethical status depends on judgments about *potential* harms and *potential* participants: not only what did happen, but what could have happened. The potential harm diagnosand might be formalized as the maximum harm that could eventuate under any realization of the data strategy. Researchers could then follow a minimax redesign procedure to find the design that minimizes this maximum potential harm.

When the design is diagnosed, we can characterize the ethical status of possible realizations of the design as well as the ethical status of the *distribution* of these realizations. Is the probability of harm minimal "enough"? Is the degree of informed consent sufficient? Given that these characteristics vary across designs and across realizations of the same design, writing down concretely both the measure of the ethical status and the ethical threshold can help structure thinking. These diagnoses and the considerations that inspire them can be shared in funding proposals, preanalysis plans, or other report. Articulating them in a design may help clarify whether proper account was taken of risks ex ante, or, more usefully, remind researchers to be sure to take account of them.

## Illustration: Estimating expected costs and expected learning

We illustrate how researchers can weigh the tradeoffs between the value of research and its ethical costs with a hypothetical audit study of discrimination in government hiring. We imagine that three characteristics of applicants to a municipal government job are randomized and whether the applicant receives a callback is recorded. The three candidate characteristics are race (Black or White), area or residence (urban or suburban), or high school attended (East or West).

Suppose we could rank the scientific importance of measuring discrimination along all three dimensions and we judged race-based discrimination of high importance and discrimination on the basis of residence or high school to be medium and low importance, respectively. 

The value of the research then is a function of the importance of the inquiries of course, but also how much we learn about it. We proxy for the learning from the experiment by sample size: the higher the $N$, the more we learn, but with decreasing marginal returns (it's a lot better to have a sample of 100 compared to 10; it matters less if it 1010 or 1100). Figure @fig-ch12num1 shows the three expected learning curves labeled by the importance of the inquiry.

Turning now to the expected costs side of the calculation. Because the job applicants are fictitious but appear real, alongside concerns around deception, a primary ethical concern in audit experiments is how much time hiring managers waste reviewing fictitious applications. In the case of government hiring, it is public money spent on their review. Suppose the cost to participants is linear in the number of applications since application takes about ten minutes to review. We represent the cost to participants as the purple line in Figure @fig-ch12num1.

We have placed the costs to participants on the same scale as the value of the research, by placing a value to society of the research and a value to society of the administrative time. When benefit exceeds cost (upper blue region), we decide to move forward with the research; if costs exceed benefits (lower gray region), we do not conduct the study.

The key take away from the graph is that there is a region at low sample sizes where the cost to participants exceed the benefits from the research, because of the very imprecise answers we get from the research. We don't learn enough about the inquiry, despite its importance, to make it worth wasting the hiring managers time. In the medium importance cases there is a "goldilocks" range: there a region of the benefits curve (highlighted in blue) where it is worth doing the study, but two regions (highlighted in gray) above and below it where it is not worth it. The left region is where the sample is too small so the value of the research is low both because of its medium importance and we do not learn enough about it. The second gray region at right in the medium importance curve is where though we learn a lot about the inquiry, the cost is too high from the many hours of hiring manager time to justify what we learn because the inquiry is not important enough.

In short, in principle, ethical decisions can be informed by diagnosis both of how much we learn and how much it costs to participants (along with other ethical costs). The key gain comes from getting a sharper understanding of the gains from design decisions on the research side; the problem of placing value on those gains is not addressed within the framework of course.

Calculations of this form however always open up risks that researchers overestimate the importance of their research or are blind to  ethical costs (in this case for instance an additional cost might arise if because of the study subjects, or other officials, became more skeptical of future real applicants). In practice strategies that maximize autonomy for implicated actors can make these choices easier. In this case for instance if prior consultations with members of the subject population that assessed how *they* saw the benefits of the research relative to the costs, and how they assessed the costs from this type of deception, would go a long way to ally ethical concerns. 

![Tradeoffs between ethical costs and scientific benefits. A design might have too *many* subjects but also too *few* subjects.](/figures/figure-21-1){#fig-ch21num1}

## Institutional review boards

When researchers sit at universities in the United States, research must be approved by the university's institutional review board (IRB) under the federal regulation known as the "Common Rule." Similar research review bodies exist at universities worldwide and at many independent research organizations and think tanks. Though these boards are commonly thought to judge research ethics, but they have a second function  to protect their institution from liability for research gone awry [@King2015, @schrag2010ethical]. Insofar as institutional and ethical goals are aligned, IRBs help ensure responsible research practices, but as a general matter institutional approval is not a substitute for ethical engagement by researchers. 
