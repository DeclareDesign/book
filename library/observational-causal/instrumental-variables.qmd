# Instrumental variables  {.unnumbered}

```{r}
#| echo: false
#| include: false
#| purl:  false
source("scripts/before_chapter_script.R")
```

:::: {.ddbox}
We declare a design in which a researcher addresses confounding concerns by using an instrumental variable. Under the right conditions, the approach can generate unbiased estimates for treatment effects for units whose treatment status is sensitive to the instrument. 
::::

When we cannot credibly assert that we have controlled for all confounding variables as in a selection-on-observables design (see Section \@ref(selection-on-observables)) and when we do not think the parallel trends assumption is likely to hold in a difference-in-differences design (see Section \@ref(difference-in-differences)), we might have to give up on our goal of drawing causal inferences. 

But occasionally, the world yields an opportunity to sidestep unobserved confounding by generating as-if random variation in a variable that itself affects the treatment variable but does not directly affect the outcome. We call the variable that is as-if randomly assigned by the world an "instrument." 

Instruments are special. They are variables that are randomly assigned by nature, the government, or other individuals or groups. Usually, genuine random assignments have to be crafted by researchers as part of a deliberate data strategy. Experimenters go to great lengths to randomly expose some units but not others to treatments. When the world provides bona fide random variation in an instrumental variable, it's a rare and valuable opportunity. By virtue of as-if random assignment, we can learn about the average causal effects of the instrument itself without any further consternation. Conditional on geography and season, weather conditions are as-if randomly assigned, so we can learn about the average effects of rainfall on many outcomes, like crop yields, voter turnout, and attendance at sporting events. Conditional on gender and birth year, draft numbers are randomly assigned by the government, so we can learn about the average effects of being drafted on educational attainment, future earnings, or public policy preferences. 

We illustrate the logic of instrumental variables with the DAG shown in Figure \@ref(fig:figure-16-7). An instrument $Z$ affects an endogenous treatment $D$ which subsequently affects an outcome $Y$. Many other common causes, summarized in terms of unknown heterogeneity $U$, affect both $D$ and $Y$. It is because of this unmeasured confounding that we cannot learn about the effect of $D$ on $Y$ directly using standard tools.

```{r figure-16-7, fig.cap = "Directed acyclic graph of an instrumental variables design.", echo = FALSE}
imgsufx <- if(is_html_output()) "svg" else "pdf"
include_graphics(path = paste0("figures/figure_16.7.", imgsufx))
```

We can naturally imagine an inquiry that represents the effect of the instrument ($Z$) on an outcome of interest such as the effect of the draft number on future earnings. In the terminology of instrumental variables, this inquiry is called the "reduced form" or the  "intention-to-treat" (ITT) effect. If it's really true that the instrument is randomly assigned by the world, estimation of the reduced form effect is straightforward: we estimate the causal effect of $Z$ on $Y$ using, for example, a difference-in-means estimator. Sometimes, we are also interested in the "first-stage" effect of the instrument on the treatment variable. Similarly, we can target this inquiry by studying the causal effect of $Z$ on $D$, for example using the difference-in-means estimator again.

The trouble comes when we want to leverage the random assignment of the instrument ($Z$) to learn about the average causal effect of the treatment variable ($D$) on the outcome ($Y$), where $D$ is not randomly assigned but rather affected by $Z$ and also other variables. To do so, we need to understand better how the instrument affects whether units are *treated* and then how both affect the outcome of interest. We need to understand "compliance" with the instrument.

We can define the compliance types of units in terms of the combinations of values the potential outcomes of $D$ take on as a function of the values of the instrument $Z$. The combinations are made up of the value of the treatment if unit $i$ is assigned to control ($D_i(Z_i = 0)$) and the value if it is assigned to treatment ($D_i(Z_i = 1)$). With a binary instrument and binary treatment, there are four possible potential outcomes values and thus four types, enumerated in Table \@ref(tab:compliancetypes). These compliance types are sometimes known as "principal strata" [@frangakis2002principal]. 

| Type          | $D_i(Z_i = 0)$   | $D_i(Z_i = 1)$   |
|---------------|------------------|------------------|
| Never-taker   | 0                | 0                |
| Complier      | 0                | 1                |
| Defier        | 1                | 0                |
| Always-taker  | 1                | 1                |

Table: (\#tab:compliancetypes) Compliance types

Never-takers are those who never take the treatment, no matter what the value of the instrument. Compliers take the value of the treatment they are assigned by the instrument. Defiers do exactly the opposite. When the instrument assigns them to take the treatment, defiers refuse it, but if it assigns them not to, they do take treatment. Like their name suggests, always-takers take the treatment regardless of the value of the instrument.

With these types in mind, we can now define a new inquiry that we will be able to target with instrumental variables under a special set of assumptions: a "local" average treatment effect (LATE) among compliers. The "local" qualifier indicates that the effect applies only to the specific group of units whose treatment status changes as a result of the instrument. The LATE is $\E[Y_i(D_i = 1) - Y_i(D_i = 0) | D_i(Z_i = 1) > D_i(Z_i = 0)]$. This quantity is the average treatment effect among the compliers. The LATE is different from the ATE because it does not average over the effects for never-takers, always-takers, and defiers, but the ATE does. 

We can adopt an instrumental variables answer strategy --- using two-stage least squares for example --- to estimate the LATE. But to do so without bias, we need to invoke new assumptions on top of those for randomized experiments. In the case of a binary instrument and a binary treatment, the five assumptions are:

1. Exogeneity of the instrument: $Y_i(D_i = 1), Y_i(D_i = 0), D_i(Z_i = 1), D_i(Z_i = 0) \indep Z_i | X_i$. Substantively, this assumption requires that (possibly conditional on observed covariates in $X$) the instrument is as-if randomly assigned, so it is jointly independent of the treated and untreated potential outcomes as well as the potential values the treatment variable $D$ would take on depending on the values of the instrument $Z$. Exogeneity is usually justified on the basis of qualitative knowledge about why as-if random assignment is a reasonable assumption to make. The assumption can be bolstered --- but not directly tested --- with design checks like whether pre-treatment values of the covariates are balanced across the levels of the instrument.

2. Excludability of the instrument: $Y_i(D_i(Z_i), Z_i) = Y_i(D_i(Z_i))$. We can "exclude" the instrument from the potential outcomes function $Y_i()$, so the only relevant argument is the value of the treatment variable. Substantively, this means that $Z$ has exactly no effect on $Y$ except by changing the value of $D$, or in other words a "total mediation assumption." Under the exclusion restriction, the effect of the instrumental variable is wholly mediated by the treatment variable. The validity of the exclusion restriction cannot be demonstrated empirically and typically must be asserted on qualitative grounds. Since the reduced form of the instrument can be estimated for many different outcome variables, one piece of evidence that can bolster the exclusion restriction is to show that the instrument does not affect other plausible causal precedents of the outcome variable. If it does affect other variables that might, in turn, affect the outcome, the exclusion restriction might be an implausible assumption.

3. Non-interference: $Y(D_i(Z_i), D_{-i}, Z_{-i}) = Y(D_i(Z_i))$. Like any non-interference assumption, here we assert that for any particular unit, other units' values of the instrument or the treatment do not affect the outcome. 

4. Monotonicity: $D_i(Z_i = 1) \geq D_i(Z_i = 0), \forall_i$. This assumption states that the effect of the instrument on the treatment is either zero or is positive for all units. Monotonicity rules out defiers. Monotonicity is usually quite plausible (it's tough to imagine a person who *would* serve in the military if not drafted but *would not* serve if drafted!), but it's not possible to affirm empirically. An empirical test that demonstrates a positive effect of the instrument on the treatment for one group but a negative effect for a different group could, however, falsify the monotonicity assumption.

5. Non-zero effect of the instrument on the treatment. If the instrument does not affect the treatment, then it is useless for learning about the effects of the treatment on the outcome, simply because it generates no compliers. If there are no compliers, the LATE itself is undefined. 

If all five of these assumptions are met, it can be shown that the inquiry $\mathrm{LATE} = \frac{\mathrm{ATE}_{ \mathrm{Z\rightarrow Y} }}{\mathrm{ATE}_{Z\rightarrow D}} = \frac{\mathrm{Reduced~Form}}{\mathrm{First~Stage}}$. It is the quotient of the ATE of the instrument on the outcome divided by the ATE of the instrument on the treatment. This expression underlines the importance of the fifth assumption: if the instrument doesn't affect the treatment, the first stage is equal to zero and the ratio is undefined. 

Many of the five assumptions are represented in the DAG in Figure \@ref(fig:figure-16-7). The exogeneity of the instrument is represented by the exclusion of a causal effect of $U$ on $Z$. The omission of an arrow from $Z$ to $Y$ directly invokes the exclusion restriction. Non-interference is typically not directly represented in DAGs. Monotonicity and the non zero effect of the instrument on the treatment is represented by the causal arrow from $Z$ to $D$.

Moving to the answer strategy, a plug-in estimator of the LATE is the difference-in-means of the outcome according to the instrument divided by the difference-in-means of the treatment according to the instrument. Equivalently, we can use two-stage least squares, which will yield the identical answer as the ratio of the difference-in-means estimates when no covariates are included in the regression.

With the four elements of the design in hand, we declare the model in code, invoking each of the five assumptions in doing so:

:::{.definition #declaration-16-4}

Instrumental variables design

```{r, file = "scripts_declarations/declaration_16.4.R"}
```

:::

The exclusion restriction is invoked in omitting a causal direct effect of $Z$ in the $Y$ potential outcomes. We invoke the monotonicity and non-zero effect of $Z$ on $D$ in the $D$ potential outcomes, which have an effect of $Z$ of 1. We invoke the non-interference assumption by excluding effects of the instrument values from other units in the definition of the $D$ and $Y$ potential outcomes. And we invoke the ignorability of $Z$ by randomly assigning it in the assignment step.

How can you use this declaration? Many instrumental variables designs involve historical data, such that most remaining design choices are in the answer strategy. Declaring and diagnosing the design can yield insights about how to construct standard errors and confidence intervals and the implications of analysis procedures in which data-dependent tests are run before fitting instrumental variables models --- and only fit if the tests pass. But other instrumental variables papers involve prospective data collection, in which an instrument is identified and outcome data (and possibly instrument and treatment data) are collected anew. In such settings, the design diagnosis and redesign tools are just as useful as in any prospective research design: to help select sampling and measurement procedures from the sample size to the number of outcomes to be collected. The key in this case is to build in the features of the instrument, the potential outcomes of treatment receipt, and the potential outcomes of the ultimate outcome of interest and to explore violations of the five assumptions in the model. 

## Design examples

- @nellis_siddiqui_2018 instrument for the share of secular legislators with the as-if randomly assigned victory of secularist candidates in close elections. The authors use this instrument to study the causal effect of secular legislators on religious violence in Pakistan.

- @Stokes2016 studies the causal effects of wind turbines on voting for incumbents, instrumenting for the presence or absence of wind turbines with plausibly exogeneous differences in wind speeds across localities.

